##  nlp demo

### nltk安装说明
- `pip install nltk`安装`nltk`，然后下载`nltk`语料包
```python
import nltk
nltk.download()
# windows会弹出图形化界面，可以选择下载的镜像以及存放位置
```

### 使用每天25条新闻预测道琼斯指数涨跌
#### Word3Vec词向量的表示方法
- one-hot representation：

用一个很长的向量来表示一个词，向量的长度为词典的大小，向量的分量只有一个 1，其他全为 0， 1 的位置对应该词在词典中的位置，缺点是收到维数灾难的影响和不能很好地刻画词与词之间的相似性

- Distributed Representation

直接用一个普通的向量表示一个词（表示方法需要训练），维度自己定义，将所有这些向量放在一起形成一个词向量空间，而每一向量则为该空间中的一个点，在这个空间上的词向量之间的距离度量也可以表示对应的两个词之间的“距离”。所谓两个词之间的“距离”，就是这两个词之间的语法，语义之间的相似性。”用一个词附近的其他词可以表示该词“。

> 可能比较抽象，举个具体的例子就是，如果我不了解你，那么我可以通过你周围的朋友来定义你是个什么样的人，有什么兴趣爱好，
> 从而了解到你，词也一样，我不知道这个词有什么含义，那么我可以通过经常与你一起出现的几个词来明白该词的含义，
> 这也是Distributed Representation可以表示一个词的核心理念


#### Word3Vec词向量语言模型
- 如果是用一个词语作为输入，来预测它周围的上下文，那这个模型叫做『Skip-gram 模型』
- 而如果是拿一个词语的上下文作为输入，来预测这个词语本身，则是 『CBOW 模型』

